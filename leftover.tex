\large Abstract
Many applications, such as data integration, search, and interlinking, may not take the full advantage of the data without having a priori statistical information about its internal structure and coverage.
In fact, there are already a number of tools, which offer such statistics, providing basic information about RDF datasets and vocabularies.
However, those usually show severe deficiencies in terms of performance once the dataset size grows beyond the capabilities of a single machine.
Within this thesis, we introduce a software component for statistical calculations of large RDF datasets, which scales out to clusters of machines.
In particular, we describe the first distributed in-memory approach for computing 32 different statistical criteria for RDF datasets using Apache Spark.
The preliminary results show that our distributed approach improves upon a previous centralized approach we compare against and provides approximately linear horizontal scale-up. 
The criteria are extensible beyond the 32 default criteria, is integrated into the larger SANSA framework and employed in at least four major usage scenarios beyond the SANSA community.

Such applications may suffer from low quality and not being able to leverage the full advantage of the data when the size of data goes beyond the capacity of the resources available.
There exist a few approaches for the quality assessment of Linked Data, but their performance degrades with the increase in data size and quickly grows beyond the capabilities of a single machine.
In this thesis, we present DistQualityAssessment -- an open-source 
implementation of quality assessment of large RDF datasets that can scale out to a cluster of machines.
This is the first distributed, in-memory approach for computing different quality metrics for large RDF datasets using Apache Spark. We also provide a quality assessment pattern that can be used to generate new scalable metrics that can be applied to big data.
The work presented here is integrated with the SANSA framework and has been applied to at least three use cases beyond the SANSA community.   
The results show that our approach is more generic, efficient, and scalable as compared to previously proposed approaches.

With the knowledge of the internals of the dataset (via statistical-driven) and it's quality we want to explore and retrieve large amounts of information.
As a result, the efficient processing of such big RDF datasets has become challenging.
Indeed, these processes require, both efficient storage strategies and query-processing engines, to be able to scale in terms of data size.
In this study, we propose a scalable approach to evaluate SPARQL queries over distributed RDF datasets using a semantic-based partition and is implemented inside the state-of-the-art RDF processing framework: SANSA.
An evaluation of the performance of our approach in processing large-scale RDF datasets is also presented. 
The preliminary results of the conducted experiments show that our approach can scale horizontally and perform well as compared with the previous Hadoop-based system.
It is also comparable with the in-memory SPARQL query evaluators when there is less shuffling involved.
As one of the main drawbacks of the semantic-based approach was the joint optimizations, during this thesis we evaluate and propose Sparklify: a scalable software component for efficient evaluation of SPARQL queries over distributed RDF datasets. 
It uses SPARQL-to-SQL rewriter techniques for translating SPARQL queries into Spark executable code.
Our preliminary results demonstrate that our approach is more extensible, efficient, and scalable as compared to state-of-the-art approaches.
Sparklify is integrated into a larger SANSA framework and it serves as a default query engine and has been used by at least three external use scenarios.