\large Abstract
Many applications, such as data integration, search, and interlinking, may not take the full advantage of the data without having a priori statistical information about its internal structure and coverage.
In fact, there are already a number of tools, which offer such statistics, providing basic information about RDF datasets and vocabularies.
However, those usually show severe deficiencies in terms of performance once the dataset size grows beyond the capabilities of a single machine.
Within this thesis, we introduce a software component for statistical calculations of large RDF datasets, which scales out to clusters of machines.
In particular, we describe the first distributed in-memory approach for computing 32 different statistical criteria for RDF datasets using Apache Spark.
The preliminary results show that our distributed approach improves upon a previous centralized approach we compare against and provides approximately linear horizontal scale-up. 
The criteria are extensible beyond the 32 default criteria, is integrated into the larger SANSA framework and employed in at least four major usage scenarios beyond the SANSA community.

Such applications may suffer from low quality and not being able to leverage the full advantage of the data when the size of data goes beyond the capacity of the resources available.
There exist a few approaches for the quality assessment of Linked Data, but their performance degrades with the increase in data size and quickly grows beyond the capabilities of a single machine.
In this thesis, we present DistQualityAssessment -- an open-source 
implementation of quality assessment of large RDF datasets that can scale out to a cluster of machines.
This is the first distributed, in-memory approach for computing different quality metrics for large RDF datasets using Apache Spark. We also provide a quality assessment pattern that can be used to generate new scalable metrics that can be applied to big data.
The work presented here is integrated with the SANSA framework and has been applied to at least three use cases beyond the SANSA community.   
The results show that our approach is more generic, efficient, and scalable as compared to previously proposed approaches.

With the knowledge of the internals of the dataset (via statistical-driven) and it's quality we want to explore and retrieve large amounts of information.
As a result, the efficient processing of such big RDF datasets has become challenging.
Indeed, these processes require, both efficient storage strategies and query-processing engines, to be able to scale in terms of data size.
In this study, we propose a scalable approach to evaluate SPARQL queries over distributed RDF datasets using a semantic-based partition and is implemented inside the state-of-the-art RDF processing framework: SANSA.
An evaluation of the performance of our approach in processing large-scale RDF datasets is also presented. 
The preliminary results of the conducted experiments show that our approach can scale horizontally and perform well as compared with the previous Hadoop-based system.
It is also comparable with the in-memory SPARQL query evaluators when there is less shuffling involved.
As one of the main drawbacks of the semantic-based approach was the joint optimizations, during this thesis we evaluate and propose Sparklify: a scalable software component for efficient evaluation of SPARQL queries over distributed RDF datasets. 
It uses SPARQL-to-SQL rewriter techniques for translating SPARQL queries into Spark executable code.
Our preliminary results demonstrate that our approach is more extensible, efficient, and scalable as compared to state-of-the-art approaches.
Sparklify is integrated into a larger SANSA framework and it serves as a default query engine and has been used by at least three external use scenarios.


% QUery 

One of the key features of Big Data is its complexity in terms of representation, structure, or formats.
One existing way to deal with it is offered by Semantic Web standards.
Among them, \gls{RDF} --which proposes to model data with triples representing edges in a graph-- has received a large success and the semantically annotated data has grown steadily towards a massive scale.
Therefore, there is a need for scalable and efficient query engines capable of retrieving such information.

Recently, significant amounts of data have been created, published and managed using the Semantic Web standards.
Currently, the \gls{LOD} cloud comprises more than 10\,000 datasets available online\furl{http://lodstats.aksw.org/} using the Semantic Web standards. 
\gls{RDF} is a standard that represents data linked as a graph of resources following the idea of the linking structure of the Web and using \gls{URI}s for representation.
To facilitate better maintenance and faster access to this scale of data, efficient data partitioning is needed.
One of such partitioned strategies is semantic-based partitioning. 
It groups the facts based on the subject and its associated triples.
We want to explore and evaluate the effect of semantic-based partitioning on query performance when dealing with such a volume of \gls{RDF} datasets.

\gls{SPARQL} is a \gls{W3C} standard query language for querying data modeled as \gls{RDF}.
Querying \gls{RDF} data efficiently becomes challenging when the size of the data increases.
This has motivated a considerable amount of work on designing distributed \gls{RDF} systems able to efficiently evaluate \gls{SPARQL} queries (\cite{Schatzle:2016:SRQ:2977797.2977806,sparqlgx-iswc-2016}).
Being able to query a large amount of data in an efficient and faster way is one of the key requirements for every \gls{SPARQL} engine.


To facilitate better maintenance and faster access to this scale of data, efficient data partitioning is needed.
One of such partitioned strategies is semantic-based partitioning. 
It groups the facts based on the subject and its associated triples.
We want to explore and evaluate the effect of semantic-based partitioning on query performance when dealing with such a volume of \gls{RDF} datasets.